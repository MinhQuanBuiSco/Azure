# RAG Application with Entity Extraction & Multi-Strategy Search

Enterprise-grade RAG (Retrieval Augmented Generation) application with budget-optimized architecture, entity extraction using GPT-4o-mini, and multiple search strategies.

## ğŸ¯ Features

### Core Capabilities
- **PDF Processing**: Upload, extract text, and chunk documents
- **Entity Extraction**: GPT-4o-mini structured outputs extract people, organizations, locations, dates, topics, and technical terms
- **Multi-Strategy Search**:
  - **BM25**: Traditional keyword search
  - **Semantic**: Vector similarity with embeddings
  - **Entity**: Filter by extracted entities
  - **Hybrid**: BM25 + Semantic (RRF fusion) - **Recommended**
  - **Advanced**: All methods combined with entity boosting
- **RAG Query**: Retrieve relevant chunks and generate answers using GPT-4o-mini
- **Redis Semantic Caching**: 70% cost reduction on repeated queries
- **Real-time Indexing Progress**: Live updates on entity extraction and embedding generation

### Technical Highlights
- Budget-optimized: **~$1,150/month** for 30,000 users
- Scales 0-50 replicas with Azure Container Apps
- Production-ready Docker containers
- Full TypeScript frontend with Tailwind CSS
- Comprehensive API documentation (Swagger/ReDoc)

## ğŸ—ï¸ Architecture

```
Frontend (React + Tailwind)
    â†“
Azure Static Web Apps / CDN
    â†“
Azure Container Apps (FastAPI Backend)
    â”œâ”€â”€ Azure Blob Storage (PDF files)
    â”œâ”€â”€ Azure AI Search (Vector + BM25 + Entities)
    â”œâ”€â”€ Azure OpenAI (GPT-4o-mini + text-embedding-3-small)
    â””â”€â”€ Azure Redis Cache (Semantic cache)
```

## ğŸ“ Project Structure

```
Azure_RAG/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ src/backend/
â”‚   â”‚   â”œâ”€â”€ api/routes/     # API endpoints
â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic models
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ entity_extractor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”‚   â”‚   â””â”€â”€ cache_service.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml      # uv dependencies
â”‚
â”œâ”€â”€ frontend/                # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ services/       # API client
â”‚   â”‚   â”œâ”€â”€ types/          # TypeScript types
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ nginx.conf
â”‚
â””â”€â”€ azure_infra/             # Terraform (pending)
    â””â”€â”€ modules/
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Node.js 20+
- Docker (optional)
- Azure account with:
  - Azure OpenAI Service
  - Azure AI Search
  - Azure Blob Storage
  - Azure Redis Cache

### Backend Setup

```bash
cd backend

# Install dependencies with uv
uv sync

# Configure environment
cp .env.example .env
# Edit .env with your Azure credentials

# Run locally
uv run uvicorn backend.main:app --reload

# Or with Docker
docker build -t rag-backend .
docker run -p 8000:8000 --env-file .env rag-backend
```

API will be available at:
- **API**: http://localhost:8000
- **Swagger Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Set VITE_API_BASE_URL=http://localhost:8000

# Run development server
npm run dev

# Or build for production
npm run build

# Or with Docker
docker build -t rag-frontend .
docker run -p 80:80 rag-frontend
```

Frontend will be available at http://localhost:5173 (dev) or http://localhost (production)

## ğŸ“š API Endpoints

### Upload
- `POST /api/upload` - Upload PDF file

### Indexing
- `POST /api/index/{document_id}` - Start indexing with entity extraction
- `GET /api/index/{document_id}` - Get indexing status and progress

### Query
- `POST /api/query/search` - Multi-strategy search
  ```json
  {
    "query": "What are the findings?",
    "strategy": "hybrid",
    "top_k": 5,
    "include_entities": true
  }
  ```

- `POST /api/query/rag` - RAG query with answer generation
  ```json
  {
    "query": "Summarize the key points"
  }
  ```

### Health
- `GET /health` - Service health check

## ğŸ’° Cost Breakdown (30,000 Users)

| Service | Configuration | Monthly Cost |
|---------|---------------|--------------|
| Azure Container Apps | 1vCPU, 2GB, ~5 replicas | $530 |
| Azure Redis Cache | Standard C1 (1GB) | $75 |
| **Azure OpenAI** | GPT-4o-mini + embeddings | **$165** |
| Azure AI Search | Standard S1 | $245 |
| Azure Blob Storage | Hot tier | $5 |
| Static Web Apps | Standard | $9 |
| Azure Front Door | Standard CDN | $75 |
| Application Insights | Pay-as-you-go | $20 |
| Data Transfer | Egress | $30 |
| **Total** | | **$1,154/month** |

**Key Cost Optimizations:**
- GPT-4o-mini instead of GPT-4o (saves $2,115/month)
- Redis semantic caching (saves 70% on LLM calls)
- Container Apps scale-to-zero capability
- Efficient chunking and embeddings

## ğŸ”§ Configuration

### Backend Environment Variables

See `backend/.env.example` for all available options:

```env
# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# Azure AI Search
AZURE_SEARCH_ENDPOINT=https://your-search.search.windows.net
AZURE_SEARCH_API_KEY=your_key
AZURE_SEARCH_INDEX_NAME=rag-index

# Azure Blob Storage
AZURE_STORAGE_CONNECTION_STRING=your_connection_string
AZURE_STORAGE_CONTAINER_NAME=pdfs

# Redis Cache
REDIS_HOST=your-redis.redis.cache.windows.net
REDIS_PORT=6380
REDIS_PASSWORD=your_password
REDIS_SSL=True

# Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
ENTITY_EXTRACTION_ENABLED=True
```

## ğŸ¨ Frontend Features

1. **PDF Upload**: Drag-and-drop interface with progress tracking
2. **Indexing Status**: Real-time progress with entity extraction count
3. **Search Strategy Selector**: Easy switching between 5 search methods
4. **Chat Interface**: Natural language queries
5. **Results Display**: Answers with confidence scores and sources
6. **Entity Highlights**: View extracted entities in results
7. **Cache Indicators**: Visual feedback for cached responses

## ğŸ§ª Search Strategies Explained

### Hybrid (Recommended)
Combines BM25 keyword search + semantic vector search using Reciprocal Rank Fusion (RRF). Best overall performance for most queries.

### Semantic
Pure vector similarity using text-embedding-3-small. Great for conceptual queries and finding similar meanings.

### BM25 (Keyword)
Traditional full-text search. Best for exact term matching, names, and IDs.

### Entity
Filters results based on extracted entities (people, organizations, topics). Requires entity filters to be specified.

### Advanced
All methods combined with custom scoring and entity boosting. Maximum precision, slightly slower.

## ğŸ“Š Monitoring

The application includes built-in health checks and can integrate with Azure Application Insights for:
- Request/response times
- Error rates
- Cache hit rates
- OpenAI token usage
- Search query patterns

## ğŸ”’ Security

- Managed Identity for Azure service authentication (no keys in code)
- CORS configuration
- Input validation
- File size limits
- Non-root Docker containers
- Azure Front Door WAF protection
- SSL/TLS encryption

## ğŸš¢ Deployment

### Option 1: Automated Terraform Deployment (Recommended)

Deploy the entire infrastructure with one command:

```bash
cd azure_infra

# 1. Configure your variables
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars with unique names

# 2. Run automated deployment
./deploy.sh
```

The script will:
- âœ… Provision all Azure resources (15-20 min)
- âœ… Create AI Search index with entity fields
- âœ… Build and push Docker images to ACR
- âœ… Deploy backend to Container Apps
- âœ… Generate backend `.env` file automatically

**Manual steps:**
1. Deploy frontend to Static Web App
2. Verify deployment health checks

See `azure_infra/README.md` for detailed documentation.

### Option 2: Manual Terraform Deployment

```bash
cd azure_infra

# Initialize
terraform init

# Plan
terraform plan -out=tfplan

# Apply
terraform apply tfplan

# Create AI Search index
cd modules/ai_search
SEARCH_SERVICE_NAME=<name> SEARCH_ADMIN_KEY=<key> ./create_index.sh

# Build and push images
docker build -t <acr-server>/rag-backend:latest ../backend
docker push <acr-server>/rag-backend:latest
```

## ğŸ—ï¸ Terraform Infrastructure

Complete infrastructure as code in `azure_infra/`:

**Resources Provisioned:**
- âœ… Resource Group
- âœ… Azure Storage Account (Blob)
- âœ… Azure Redis Cache (Standard C1)
- âœ… Azure AI Search (Standard S1) with entity-aware index schema
- âœ… Azure OpenAI (GPT-4o-mini + text-embedding-3-small)
- âœ… Azure Container Registry
- âœ… Azure Container Apps Environment + Backend App (3-50 replicas)
- âœ… Azure Static Web App
- âœ… Application Insights + Log Analytics

**Features:**
- Auto-scaling configuration
- Secure secret management
- Health checks and monitoring
- CORS and networking
- Cost-optimized SKUs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- Built with FastAPI, React, and Azure services
- Entity extraction powered by GPT-4o-mini
- Search powered by Azure AI Search
- Caching by Azure Redis

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check the API documentation at `/docs`
- Review Azure service documentation

---

**Budget-optimized â€¢ Production-ready â€¢ Enterprise-scale**
